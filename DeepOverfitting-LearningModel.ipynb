{
  "cells":[
    {
      "cell_type":"code",
      "source":[
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.base import clone"
      ],
      "execution_count":1,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Обучение модели"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Вспомогательные функции"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def compute_meta_feature(clf, X_train, X_test, y_train, cv):\n",
        "    \"\"\"\n",
        "    Computes meta-features using the classifier.\n",
        "    \n",
        "    :arg clf: scikit-learn classifier\n",
        "    :args X_train, y_train: training set\n",
        "    :arg X_test: testing set\n",
        "    :arg cv: cross-validation folding\n",
        "    \"\"\"\n",
        "    X_meta_train = np.zeros_like(y_train, dtype=np.float32)\n",
        "    for train_fold_index, predict_fold_index in cv.split(X_train):\n",
        "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
        "        y_fold_train = y_train[train_fold_index]\n",
        "        \n",
        "        folded_clf = clone(clf)\n",
        "        folded_clf.fit(X_fold_train, y_fold_train)\n",
        "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)[:, 1]\n",
        "    \n",
        "    meta_clf = clone(clf)\n",
        "    meta_clf.fit(X_train, y_train)\n",
        "    \n",
        "    X_meta_test = meta_clf.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    return X_meta_train, X_meta_test"
      ],
      "execution_count":2,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def generate_meta_features(classifiers, X_train, X_test, y_train, cv):\n",
        "    \"\"\"\n",
        "    Generates metafeatures using a list of classifiers.\n",
        "    \n",
        "    :arg classifiers: list of scikit-learn classifiers\n",
        "    :args X_train, y_train: training set\n",
        "    :arg X_test: testing set\n",
        "    :arg cv: cross-validation folding\n",
        "    \"\"\"\n",
        "    features = [\n",
        "        compute_meta_feature(clf, X_train, X_test, y_train, cv)\n",
        "        for clf in tqdm(classifiers)\n",
        "    ]\n",
        "    \n",
        "    stacked_features_train = np.vstack([\n",
        "        features_train for features_train, features_test in features\n",
        "    ]).T\n",
        "\n",
        "    stacked_features_test = np.vstack([\n",
        "        features_test for features_train, features_test in features\n",
        "    ]).T\n",
        "    \n",
        "    return stacked_features_train, stacked_features_test"
      ],
      "execution_count":3,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Загружаем данные из pickle"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "model_file = open('processed_data.pkl', 'rb')\n",
        "data = pickle.load(model_file)\n",
        "model_file.close()\n",
        "data"
      ],
      "execution_count":4,
      "outputs":[
        {
          "data":{
            "text\/html":[
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "<\/style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th><\/th>\n",
              "      <th>duration<\/th>\n",
              "      <th>rounds<\/th>\n",
              "      <th>f1_age<\/th>\n",
              "      <th>f2_age<\/th>\n",
              "      <th>f1_isHomeCity<\/th>\n",
              "      <th>f1_isHomeCountry<\/th>\n",
              "      <th>f1_isHomeTimezone<\/th>\n",
              "      <th>f2_isHomeCity<\/th>\n",
              "      <th>f2_isHomeCountry<\/th>\n",
              "      <th>f2_isHomeTimezone<\/th>\n",
              "      <th>...<\/th>\n",
              "      <th>grappling_accuracy_difference<\/th>\n",
              "      <th>hitsTotal_difference<\/th>\n",
              "      <th>takedownTotal_difference<\/th>\n",
              "      <th>submissionAttempts_difference<\/th>\n",
              "      <th>takeovers_difference<\/th>\n",
              "      <th>hitsBodyTotal_difference<\/th>\n",
              "      <th>hitsLegsTotal_difference<\/th>\n",
              "      <th>weight_difference<\/th>\n",
              "      <th>height_difference<\/th>\n",
              "      <th>legSwing_difference<\/th>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>id<\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "      <th><\/th>\n",
              "    <\/tr>\n",
              "  <\/thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5201<\/th>\n",
              "      <td>104.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>27.0<\/td>\n",
              "      <td>34.0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>4.0<\/td>\n",
              "      <td>3.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>-18.6<\/td>\n",
              "      <td>-10.2<\/td>\n",
              "      <td>0.0<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>5202<\/th>\n",
              "      <td>52.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>24.0<\/td>\n",
              "      <td>23.0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>2.0<\/td>\n",
              "      <td>2.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>2.3<\/td>\n",
              "      <td>-7.6<\/td>\n",
              "      <td>0.0<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>5203<\/th>\n",
              "      <td>59.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>23.0<\/td>\n",
              "      <td>34.0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>-14.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>-2.0<\/td>\n",
              "      <td>26.8<\/td>\n",
              "      <td>-2.5<\/td>\n",
              "      <td>0.0<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>5204<\/th>\n",
              "      <td>57.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>29.0<\/td>\n",
              "      <td>27.0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>-12.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>-1.0<\/td>\n",
              "      <td>-1.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>13.6<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>5205<\/th>\n",
              "      <td>138.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>27.0<\/td>\n",
              "      <td>30.0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>7.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>2.0<\/td>\n",
              "      <td>-9.5<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>...<\/th>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>5310<\/th>\n",
              "      <td>260.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>25.0<\/td>\n",
              "      <td>25.0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>-1.0<\/td>\n",
              "      <td>19.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>7.6<\/td>\n",
              "      <td>5.1<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>6338<\/th>\n",
              "      <td>300.0<\/td>\n",
              "      <td>3.0<\/td>\n",
              "      <td>30.0<\/td>\n",
              "      <td>22.0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>71.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>-2.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>-5.1<\/td>\n",
              "      <td>-7.6<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>5311<\/th>\n",
              "      <td>300.0<\/td>\n",
              "      <td>5.0<\/td>\n",
              "      <td>31.0<\/td>\n",
              "      <td>35.0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>6.0<\/td>\n",
              "      <td>2.0<\/td>\n",
              "      <td>-1.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>2.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>-2.5<\/td>\n",
              "      <td>0.0<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>5312<\/th>\n",
              "      <td>300.0<\/td>\n",
              "      <td>3.0<\/td>\n",
              "      <td>33.0<\/td>\n",
              "      <td>33.0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>-1.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>-9.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>-5.1<\/td>\n",
              "      <td>5.2<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>6340<\/th>\n",
              "      <td>295.0<\/td>\n",
              "      <td>2.0<\/td>\n",
              "      <td>36.0<\/td>\n",
              "      <td>38.0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>1<\/td>\n",
              "      <td>0<\/td>\n",
              "      <td>...<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>-12.0<\/td>\n",
              "      <td>-2.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>3.0<\/td>\n",
              "      <td>-1.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>5.1<\/td>\n",
              "      <td>5.1<\/td>\n",
              "    <\/tr>\n",
              "  <\/tbody>\n",
              "<\/table>\n",
              "<p>6257 rows × 26 columns<\/p>\n",
              "<\/div>"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Выбираем независимые и целевую переменные"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "X = data.drop(columns=['winner'])\n",
        "y = data.winner\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count":5,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Пробуем случайный лес"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "rfc = RandomForestClassifier()\n",
        "\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rfc = rfc.predict(X_test)"
      ],
      "execution_count":6,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### F1_score метрика"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "f1_score(y_test, y_pred_rfc)"
      ],
      "execution_count":7,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "0.857469948483114"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Матрица ошибок и метрика accuracy"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "plt.figure(figsize=(10,7))\n",
        "cmd_forest = confusion_matrix(y_test, y_pred_rfc)\n",
        "sns.heatmap(cmd_forest ,annot=True , fmt = 'd')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "print('Accuracy RandomForest: ', rfc.score(X_test, y_test))"
      ],
      "execution_count":8,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Accuracy RandomForest:  0.8011182108626198\n"
          ],
          "output_type":"stream"
        },
        {
          "data":{
            "image\/png":[
              "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\n"
            ]
          },
          "metadata":{
            "image\/png":{
              "width":0,
              "height":0
            }
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Стекинг"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "stacked_features_train, stacked_features_test = generate_meta_features([\n",
        "    KNeighborsClassifier(n_jobs=-1),\n",
        "    ExtraTreesClassifier(n_estimators=300, n_jobs=-1),\n",
        "], X_train.values, X_test.values, y_train.values, cv)"
      ],
      "execution_count":9,
      "outputs":[
        {
          "name":"stderr",
          "text":[
            "\r  0%|          | 0\/2 [00:00<?, ?it\/s]\r 50%|█████     | 1\/2 [00:02<00:02,  2.25s\/it]\r100%|██████████| 2\/2 [00:28<00:00, 16.31s\/it]\r100%|██████████| 2\/2 [00:28<00:00, 14.20s\/it]\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "clf = LogisticRegression(penalty='none', solver='lbfgs')\n",
        "clf.fit(stacked_features_train, y_train)\n",
        "y_pred_clf = clf.predict(stacked_features_test)"
      ],
      "execution_count":10,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "f1_score(y_test, y_pred_clf)"
      ],
      "execution_count":11,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "0.8487584650112867"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "accuracy_score(y_test, y_pred_clf)"
      ],
      "execution_count":12,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "0.7859424920127795"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "stacked_features_train, stacked_features_test = generate_meta_features([\n",
        "    KNeighborsClassifier(n_jobs=-1),\n",
        "    RandomForestClassifier(n_estimators=300, n_jobs=-1),\n",
        "], X_train.values, X_test.values, y_train.values, cv)"
      ],
      "execution_count":13,
      "outputs":[
        {
          "name":"stderr",
          "text":[
            "\r  0%|          | 0\/2 [00:00<?, ?it\/s]\r 50%|█████     | 1\/2 [00:01<00:01,  1.72s\/it]\r100%|██████████| 2\/2 [00:26<00:00, 15.01s\/it]\r100%|██████████| 2\/2 [00:26<00:00, 13.02s\/it]\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "clf = LogisticRegression(penalty='none', solver='lbfgs')\n",
        "clf.fit(stacked_features_train, y_train)\n",
        "y_pred_clf = clf.predict(stacked_features_test)"
      ],
      "execution_count":14,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "f1_score(y_test, y_pred_clf)"
      ],
      "execution_count":15,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "0.8581314878892734"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "accuracy_score(y_test, y_pred_clf)"
      ],
      "execution_count":16,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "0.8035143769968051"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Стекинг с нормализацией данных"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "scaler = StandardScaler()\n",
        "cover_X_train = scaler.fit_transform(X_train)\n",
        "cover_X_test = scaler.transform(X_test)"
      ],
      "execution_count":17,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "stacked_features_train, stacked_features_test = generate_meta_features([\n",
        "    KNeighborsClassifier(n_jobs=-1),\n",
        "    ExtraTreesClassifier(n_estimators=300, n_jobs=-1),\n",
        "], cover_X_train, cover_X_test, y_train.values, cv)"
      ],
      "execution_count":18,
      "outputs":[
        {
          "name":"stderr",
          "text":[
            "\r  0%|          | 0\/2 [00:00<?, ?it\/s]\r 50%|█████     | 1\/2 [00:01<00:01,  1.61s\/it]\r100%|██████████| 2\/2 [00:22<00:00, 12.88s\/it]\r100%|██████████| 2\/2 [00:22<00:00, 11.19s\/it]\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "clf = LogisticRegression(penalty='none', solver='lbfgs')\n",
        "clf.fit(stacked_features_train, y_train)\n",
        "y_pred_clf = clf.predict(stacked_features_test)"
      ],
      "execution_count":19,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "f1_score(y_test, y_pred_clf)"
      ],
      "execution_count":20,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "0.8447981807845367"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "accuracy_score(y_test, y_pred_clf)"
      ],
      "execution_count":21,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "0.7819488817891374"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Пробуем XGboost classifier"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import xgboost as xgb"
      ],
      "execution_count":22,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Преобразовываем независимые и целевую переменные"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "D_train = xgb.DMatrix(X_train, label=y_train)\n",
        "D_test = xgb.DMatrix(X_test, label=y_test)"
      ],
      "execution_count":23,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Настраиваем дефолтные параметры"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "param = {\n",
        "    'eta': 0.3, \n",
        "    'max_depth': 3,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 3} \n",
        "\n",
        "steps = 20  # The number of training iterations"
      ],
      "execution_count":24,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Обучаем модель XGBoost Classifier"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "xgb_model = xgb.train(param, D_train, steps)"
      ],
      "execution_count":25,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Предсказываем целевую переменную"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "preds = xgb_model.predict(D_test)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "print(\"Accuracy = {}\".format(accuracy_score(y_test, best_preds)))"
      ],
      "execution_count":26,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Accuracy = 0.8019169329073482\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Мы пытались\n",
        "# plt.figure(figsize=(10,7))\n",
        "# cmd_xgb = confusion_matrix(D_train, D_test)\n",
        "# sns.heatmap(cmd_xgb, annot=True, fmt='d')\n",
        "# plt.xlabel('Predicted')\n",
        "# plt.ylabel('Truth')\n",
        "# print('Accuracy XGBClassifier: ', cmd_xgb.score(D_train, y_test))"
      ],
      "execution_count":27,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Всем спасибо, все идем спать!"
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}